
---
layout: post

title: 数据结构

date: 2017-03-09 15:32:24.000000000 +09:00

---

# 栈和队列

栈和队列都可以用一个数组来实现

栈的实现比较简单，记录一个top指针，push时 top++ ，pop时top--。

队列稍微复杂些，记录两个指针 head 和 tail.
enqueue入队时 取 array[tail] 并且 tail = (tail + 1)%arrayLength
dequeue出队时 取 array[head] 并且 head = (head + 1)%arrayLength
仔细想一下，这样做法可以循环利用数组，每次一出一进，前面会有用过空出的空间，但是 每次tail和head都是+1 模size，这样就能重复利用前面的空间了。注意判断size的大小，如果size大于arrayLength了就要及时扩充。

# 树

树相比于链表，再处理大量数据时，插入删除性能，查找性能，都有明显的优势。
因为将数据整合进有宽度有长度的平面图形中，数据可以依靠数节点的多条边，可以表达更多的逻辑。

### 基本含义和种类
抽象地说，基本上有序列的地方就可以应用树，因为树结构即是一种序列索引结构
传统的文件夹，就是很好的应用实例。

1. 无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树；
2. 有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树；
3. 二叉树：每个节点最多含有两个子树的树称为二叉树；
4. 完全二叉树：对于一颗二叉树，假设其深度为d（d>1）。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树；
5. 满二叉树：所有叶节点都在最底层的完全二叉树。
6. 排序二叉树(二叉查找树（英语：Binary Search Tree），也称二叉搜索树、有序二叉树)
7. 平衡二叉树（AVL树）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树。
8. 2-3树 : 一个节点可能有两到三个孩子，一或两个值，也是自平衡二叉树。
9. 红黑树：自平衡二叉树，每次插入或删除，修复自身保持左右平衡，保证检索效率
10. 霍夫曼树：带权路径最短的二叉树称为哈夫曼树或最优二叉树；
11. B树：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树


从1 到 10 是树的进化，逐步有序，有规则，查找和更新的效率更高，意义更大。

人借助计算机实现对数据的管理，其中利用树这种数据结构优势很大。既在概念上模仿了现实生活中的一些数据关系，使人更能方便理解，又在树型结构的特点是能更灵活的保证对数据的增删改查的效率。

从6开始，二叉树可以实现排序的功能，但插入和删除的效率不稳定，最坏情况退化树变成链表O(n)。因为这些操作的时间复杂度跟树的高度相关

到7的话，有了自平衡的概念，就是每次修改树都要重新恢复树的平衡，保证树的高度都差不大与1.从而保证了查找插入删除的效率最坏的情况O(logn)

到8的话，节点可以保存一或两个值，二到三个孩子，每次增删改查可以借助2节点变3节点，或者是3节点分裂成2节点，将分裂后的三个孩子中的中间值挤到上面一层的节点里，如果上面是2节点，自然变成三节点，如果上面是三节点，就再次向上面分裂。 将变化推演到上层，使其影响局部或者全局分布，这样能保证到每一个空节点到根节点的高度都是一样的。

### 优缺点

抽象地说，基本上有序列的地方就可以应用树，因为树结构即是一种序列索引结构。

序列的核心接口就是三个：插、查、删。

这个索引可以把原本O(n)的查找操作变为O(logn)，可以简单地理解为在数据结构的层面上构造了一个二分查找算法。

Hash查找(散列表) 时间复杂度 O(1)         需要开辟大量空间 
二叉树查找       时间复杂度 O(logn)      灵活控制内存
链表查找         时间复杂度 O(n)         灵活控制内存


现在很多大型高效的数据库（如mysql大多用B+树）都是利用树，因为内存控制更灵活，相比Hash表的搜索，往往适用于小范围可控的数据，因为内存上开辟开辟巨大空间，即使有扩容和重建算法效率也比较一般。
7，8，9 ，11 都是对自平衡方法的优化。

